{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从Excel文件读取数据\n",
    "excel_file = '~/视频/20240318.xlsx'\n",
    "df = pd.read_excel(excel_file, skiprows=6)\n",
    "df = df.drop(df.columns[[0,3]+list(range(5, 19, 1))+list(range(20, 51, 2))+list(range(-1, -5, -1))], axis=1)\n",
    "display(df[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:, :3].values\n",
    "labels = df.iloc[:, 3:].values\n",
    "display(data[:6], labels[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义自定义的数据集类\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# 将数据转换成自定义数据集对象\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建训练集和测试集的 Dataset 实例\n",
    "train_dataset = CustomDataset(train_data, train_labels)\n",
    "test_dataset = CustomDataset(test_data, test_labels)\n",
    "\n",
    "# 创建训练集和测试集的 DataLoader 实例\n",
    "train_iter = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_iter = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# 隐藏层包含256个隐藏单元，并使用了ReLU激活函数\n",
    "net = nn.Sequential(nn.Linear(3,64),nn.ReLU(),nn.Linear(64,16))\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight,std=0,)\n",
    "        \n",
    "net.apply(init_weights)\n",
    "\n",
    "# 训练过程\n",
    "lr, num_epochs = 0.1, 10\n",
    "loss = nn.MSELoss()\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "import time\n",
    "\n",
    "def train(net, train_iter, test_iter, loss, num_epochs, trainer):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_batches = 0.0, 0\n",
    "        start = time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y.view(-1, 1))\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_batches += 1\n",
    "        test_l_sum, test_batches = 0.0, 0\n",
    "        for X, y in test_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y.view(-1, 1))\n",
    "            test_l_sum += l.item()\n",
    "            test_batches += 1\n",
    "        print(f'epoch {epoch + 1}, '\n",
    "              f'train loss {train_l_sum / train_batches}, '\n",
    "              f'test loss {test_l_sum / test_batches}, '\n",
    "              f'time {time.time() - start} sec')\n",
    "train(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P4</th>\n",
       "      <th>P7</th>\n",
       "      <th>P9</th>\n",
       "      <th>P11</th>\n",
       "      <th>P13</th>\n",
       "      <th>P15</th>\n",
       "      <th>P17</th>\n",
       "      <th>P19</th>\n",
       "      <th>P21</th>\n",
       "      <th>P23</th>\n",
       "      <th>P25</th>\n",
       "      <th>P27</th>\n",
       "      <th>P29</th>\n",
       "      <th>P31</th>\n",
       "      <th>P33</th>\n",
       "      <th>P35</th>\n",
       "      <th>P37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>7516.780273</td>\n",
       "      <td>13103.160156</td>\n",
       "      <td>12337.788086</td>\n",
       "      <td>11112.787109</td>\n",
       "      <td>0</td>\n",
       "      <td>233.591507</td>\n",
       "      <td>208.203857</td>\n",
       "      <td>19846.021484</td>\n",
       "      <td>20093.779297</td>\n",
       "      <td>22890.263672</td>\n",
       "      <td>1136.935059</td>\n",
       "      <td>0</td>\n",
       "      <td>374.969391</td>\n",
       "      <td>103.178192</td>\n",
       "      <td>199.192825</td>\n",
       "      <td>1900.335693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0290</td>\n",
       "      <td>7186.275391</td>\n",
       "      <td>11951.074219</td>\n",
       "      <td>11195.372070</td>\n",
       "      <td>10027.208008</td>\n",
       "      <td>0</td>\n",
       "      <td>21.426411</td>\n",
       "      <td>16.606430</td>\n",
       "      <td>25453.894531</td>\n",
       "      <td>25696.455078</td>\n",
       "      <td>29353.455078</td>\n",
       "      <td>654.084229</td>\n",
       "      <td>0</td>\n",
       "      <td>125.636726</td>\n",
       "      <td>27.254568</td>\n",
       "      <td>60.425423</td>\n",
       "      <td>311.825806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5430</td>\n",
       "      <td>8334.772461</td>\n",
       "      <td>10205.735352</td>\n",
       "      <td>9503.373047</td>\n",
       "      <td>8453.971680</td>\n",
       "      <td>0</td>\n",
       "      <td>11.396958</td>\n",
       "      <td>8.823508</td>\n",
       "      <td>34507.523438</td>\n",
       "      <td>34730.593750</td>\n",
       "      <td>39791.292969</td>\n",
       "      <td>308.672150</td>\n",
       "      <td>0</td>\n",
       "      <td>44.110538</td>\n",
       "      <td>3.616076</td>\n",
       "      <td>9.274529</td>\n",
       "      <td>11.553834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>14097.777344</td>\n",
       "      <td>27233.179688</td>\n",
       "      <td>25667.646484</td>\n",
       "      <td>23144.935547</td>\n",
       "      <td>0</td>\n",
       "      <td>948.891724</td>\n",
       "      <td>811.739197</td>\n",
       "      <td>24515.419922</td>\n",
       "      <td>24728.386719</td>\n",
       "      <td>28235.431641</td>\n",
       "      <td>2786.076660</td>\n",
       "      <td>0</td>\n",
       "      <td>1253.976929</td>\n",
       "      <td>1221.493164</td>\n",
       "      <td>1620.159546</td>\n",
       "      <td>5010.981934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0290</td>\n",
       "      <td>13418.339844</td>\n",
       "      <td>26595.847656</td>\n",
       "      <td>25071.730469</td>\n",
       "      <td>22614.595703</td>\n",
       "      <td>0</td>\n",
       "      <td>625.844849</td>\n",
       "      <td>554.617920</td>\n",
       "      <td>31724.259766</td>\n",
       "      <td>31943.152344</td>\n",
       "      <td>36577.992188</td>\n",
       "      <td>2941.251709</td>\n",
       "      <td>0</td>\n",
       "      <td>1403.122559</td>\n",
       "      <td>904.027893</td>\n",
       "      <td>1234.554077</td>\n",
       "      <td>5224.838867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5430</td>\n",
       "      <td>14756.765625</td>\n",
       "      <td>25178.017578</td>\n",
       "      <td>23651.984375</td>\n",
       "      <td>21254.265625</td>\n",
       "      <td>0</td>\n",
       "      <td>563.812683</td>\n",
       "      <td>515.636658</td>\n",
       "      <td>41506.640625</td>\n",
       "      <td>41682.035156</td>\n",
       "      <td>47817.644531</td>\n",
       "      <td>2082.288330</td>\n",
       "      <td>0</td>\n",
       "      <td>931.210083</td>\n",
       "      <td>477.753845</td>\n",
       "      <td>674.120605</td>\n",
       "      <td>1666.383545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>28403.441406</td>\n",
       "      <td>42910.082031</td>\n",
       "      <td>40398.628906</td>\n",
       "      <td>36384.621094</td>\n",
       "      <td>0</td>\n",
       "      <td>7915.877930</td>\n",
       "      <td>7598.249512</td>\n",
       "      <td>33732.882812</td>\n",
       "      <td>33883.304688</td>\n",
       "      <td>38932.324219</td>\n",
       "      <td>5200.280273</td>\n",
       "      <td>0</td>\n",
       "      <td>3312.565674</td>\n",
       "      <td>4873.817383</td>\n",
       "      <td>5905.839355</td>\n",
       "      <td>13157.237305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0290</td>\n",
       "      <td>20883.005859</td>\n",
       "      <td>43746.972656</td>\n",
       "      <td>41099.746094</td>\n",
       "      <td>36929.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2258.028564</td>\n",
       "      <td>1966.789917</td>\n",
       "      <td>37490.117188</td>\n",
       "      <td>37625.765625</td>\n",
       "      <td>43107.613281</td>\n",
       "      <td>4144.259766</td>\n",
       "      <td>0</td>\n",
       "      <td>2264.598633</td>\n",
       "      <td>3531.873535</td>\n",
       "      <td>4469.514160</td>\n",
       "      <td>6066.695312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5430</td>\n",
       "      <td>20636.640625</td>\n",
       "      <td>41411.617188</td>\n",
       "      <td>38919.226562</td>\n",
       "      <td>34999.175781</td>\n",
       "      <td>0</td>\n",
       "      <td>1019.338074</td>\n",
       "      <td>869.188721</td>\n",
       "      <td>46916.523438</td>\n",
       "      <td>47079.785156</td>\n",
       "      <td>54058.324219</td>\n",
       "      <td>4208.702148</td>\n",
       "      <td>0</td>\n",
       "      <td>2176.898193</td>\n",
       "      <td>3232.098633</td>\n",
       "      <td>4087.277100</td>\n",
       "      <td>6640.703613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-45</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>275492.062500</td>\n",
       "      <td>64103.785156</td>\n",
       "      <td>64121.390625</td>\n",
       "      <td>61671.621094</td>\n",
       "      <td>0</td>\n",
       "      <td>27423.164062</td>\n",
       "      <td>27632.683594</td>\n",
       "      <td>25124.671875</td>\n",
       "      <td>25602.072266</td>\n",
       "      <td>29644.804688</td>\n",
       "      <td>69640.875000</td>\n",
       "      <td>0</td>\n",
       "      <td>71833.953125</td>\n",
       "      <td>80035.445312</td>\n",
       "      <td>81276.539062</td>\n",
       "      <td>212885.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-45</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0290</td>\n",
       "      <td>401812.437500</td>\n",
       "      <td>85573.226562</td>\n",
       "      <td>86364.367188</td>\n",
       "      <td>83777.304688</td>\n",
       "      <td>0</td>\n",
       "      <td>39570.917969</td>\n",
       "      <td>40019.027344</td>\n",
       "      <td>28198.062500</td>\n",
       "      <td>28793.021484</td>\n",
       "      <td>33408.449219</td>\n",
       "      <td>100654.390625</td>\n",
       "      <td>0</td>\n",
       "      <td>103724.968750</td>\n",
       "      <td>114405.687500</td>\n",
       "      <td>115929.835938</td>\n",
       "      <td>297440.656250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    P1   P2      P4             P7            P9           P11           P13  \\\n",
       "0    0  1.5  0.5144    7516.780273  13103.160156  12337.788086  11112.787109   \n",
       "1    0  1.5  1.0290    7186.275391  11951.074219  11195.372070  10027.208008   \n",
       "2    0  1.5  1.5430    8334.772461  10205.735352   9503.373047   8453.971680   \n",
       "3    0  2.0  0.5144   14097.777344  27233.179688  25667.646484  23144.935547   \n",
       "4    0  2.0  1.0290   13418.339844  26595.847656  25071.730469  22614.595703   \n",
       "5    0  2.0  1.5430   14756.765625  25178.017578  23651.984375  21254.265625   \n",
       "6    0  2.5  0.5144   28403.441406  42910.082031  40398.628906  36384.621094   \n",
       "7    0  2.5  1.0290   20883.005859  43746.972656  41099.746094  36929.000000   \n",
       "8    0  2.5  1.5430   20636.640625  41411.617188  38919.226562  34999.175781   \n",
       "9  -45  1.5  0.5144  275492.062500  64103.785156  64121.390625  61671.621094   \n",
       "10 -45  1.5  1.0290  401812.437500  85573.226562  86364.367188  83777.304688   \n",
       "\n",
       "    P15           P17           P19           P21           P23           P25  \\\n",
       "0     0    233.591507    208.203857  19846.021484  20093.779297  22890.263672   \n",
       "1     0     21.426411     16.606430  25453.894531  25696.455078  29353.455078   \n",
       "2     0     11.396958      8.823508  34507.523438  34730.593750  39791.292969   \n",
       "3     0    948.891724    811.739197  24515.419922  24728.386719  28235.431641   \n",
       "4     0    625.844849    554.617920  31724.259766  31943.152344  36577.992188   \n",
       "5     0    563.812683    515.636658  41506.640625  41682.035156  47817.644531   \n",
       "6     0   7915.877930   7598.249512  33732.882812  33883.304688  38932.324219   \n",
       "7     0   2258.028564   1966.789917  37490.117188  37625.765625  43107.613281   \n",
       "8     0   1019.338074    869.188721  46916.523438  47079.785156  54058.324219   \n",
       "9     0  27423.164062  27632.683594  25124.671875  25602.072266  29644.804688   \n",
       "10    0  39570.917969  40019.027344  28198.062500  28793.021484  33408.449219   \n",
       "\n",
       "              P27  P29            P31            P33            P35  \\\n",
       "0     1136.935059    0     374.969391     103.178192     199.192825   \n",
       "1      654.084229    0     125.636726      27.254568      60.425423   \n",
       "2      308.672150    0      44.110538       3.616076       9.274529   \n",
       "3     2786.076660    0    1253.976929    1221.493164    1620.159546   \n",
       "4     2941.251709    0    1403.122559     904.027893    1234.554077   \n",
       "5     2082.288330    0     931.210083     477.753845     674.120605   \n",
       "6     5200.280273    0    3312.565674    4873.817383    5905.839355   \n",
       "7     4144.259766    0    2264.598633    3531.873535    4469.514160   \n",
       "8     4208.702148    0    2176.898193    3232.098633    4087.277100   \n",
       "9    69640.875000    0   71833.953125   80035.445312   81276.539062   \n",
       "10  100654.390625    0  103724.968750  114405.687500  115929.835938   \n",
       "\n",
       "              P37  \n",
       "0     1900.335693  \n",
       "1      311.825806  \n",
       "2       11.553834  \n",
       "3     5010.981934  \n",
       "4     5224.838867  \n",
       "5     1666.383545  \n",
       "6    13157.237305  \n",
       "7     6066.695312  \n",
       "8     6640.703613  \n",
       "9   212885.640625  \n",
       "10  297440.656250  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.    , 1.5   , 0.5144],\n",
       "       [0.    , 1.5   , 1.029 ],\n",
       "       [0.    , 1.5   , 1.543 ],\n",
       "       [0.    , 2.    , 0.5144],\n",
       "       [0.    , 2.    , 1.029 ],\n",
       "       [0.    , 2.    , 1.543 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[7.51678027e+03, 1.31031602e+04, 1.23377881e+04, 1.11127871e+04,\n",
       "        0.00000000e+00, 2.33591507e+02, 2.08203857e+02, 1.98460215e+04,\n",
       "        2.00937793e+04, 2.28902637e+04, 1.13693506e+03, 0.00000000e+00,\n",
       "        3.74969391e+02, 1.03178192e+02, 1.99192825e+02, 1.90033569e+03],\n",
       "       [7.18627539e+03, 1.19510742e+04, 1.11953721e+04, 1.00272080e+04,\n",
       "        0.00000000e+00, 2.14264107e+01, 1.66064301e+01, 2.54538945e+04,\n",
       "        2.56964551e+04, 2.93534551e+04, 6.54084229e+02, 0.00000000e+00,\n",
       "        1.25636726e+02, 2.72545681e+01, 6.04254227e+01, 3.11825806e+02],\n",
       "       [8.33477246e+03, 1.02057354e+04, 9.50337305e+03, 8.45397168e+03,\n",
       "        0.00000000e+00, 1.13969584e+01, 8.82350826e+00, 3.45075234e+04,\n",
       "        3.47305938e+04, 3.97912930e+04, 3.08672150e+02, 0.00000000e+00,\n",
       "        4.41105385e+01, 3.61607575e+00, 9.27452946e+00, 1.15538340e+01],\n",
       "       [1.40977773e+04, 2.72331797e+04, 2.56676465e+04, 2.31449355e+04,\n",
       "        0.00000000e+00, 9.48891724e+02, 8.11739197e+02, 2.45154199e+04,\n",
       "        2.47283867e+04, 2.82354316e+04, 2.78607666e+03, 0.00000000e+00,\n",
       "        1.25397693e+03, 1.22149316e+03, 1.62015955e+03, 5.01098193e+03],\n",
       "       [1.34183398e+04, 2.65958477e+04, 2.50717305e+04, 2.26145957e+04,\n",
       "        0.00000000e+00, 6.25844849e+02, 5.54617920e+02, 3.17242598e+04,\n",
       "        3.19431523e+04, 3.65779922e+04, 2.94125171e+03, 0.00000000e+00,\n",
       "        1.40312256e+03, 9.04027893e+02, 1.23455408e+03, 5.22483887e+03],\n",
       "       [1.47567656e+04, 2.51780176e+04, 2.36519844e+04, 2.12542656e+04,\n",
       "        0.00000000e+00, 5.63812683e+02, 5.15636658e+02, 4.15066406e+04,\n",
       "        4.16820352e+04, 4.78176445e+04, 2.08228833e+03, 0.00000000e+00,\n",
       "        9.31210083e+02, 4.77753845e+02, 6.74120605e+02, 1.66638354e+03]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 从Excel文件读取数据\n",
    "excel_file = '~/视频/20240318.xlsx'\n",
    "df = pd.read_excel(excel_file, skiprows=6)\n",
    "df = df.drop(df.columns[[0,3]+list(range(5, 19, 1))+list(range(20, 51, 2))+list(range(-1, -5, -1))], axis=1)\n",
    "display(df[:11])\n",
    "\n",
    "data = df.iloc[:, :3].values\n",
    "labels = df.iloc[:, 3:].values\n",
    "display(data[:6], labels[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =         5600     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11570D+10    |proj g|=  2.99204D+05\n",
      "\n",
      "At iterate    1    f=  5.83083D+09    |proj g|=  7.75791D+09\n",
      "  ys=-1.195E+11  -gs= 6.984E+07 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      " 5600      2     31      2     1     0   7.758D+09   5.831D+09\n",
      "  F =   5830825047.8889980     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "Score: -0.2533623183571373\n",
      "Predictions: [[230499.37237413  62608.14724947  55597.39117355  56083.08692434\n",
      "    -912.97096085  56129.40568195  57115.70693643  39756.64403287\n",
      "   31092.65541216  41439.57361309  95466.50126776  -1213.11630691\n",
      "  101389.09613138 154440.53771756 159460.04462223 324742.08142167]\n",
      " [129848.38746745  35270.17537434  31316.02345442  31594.5118164\n",
      "    -510.30593105  31618.79812075  32177.64863556  22398.9595097\n",
      "   17516.77119732  23343.44845092  53778.48987209   -686.51530052\n",
      "   57114.85899387  86998.20892307  89831.26615278 182936.65313292]\n",
      " [109265.41187104  29679.77512459  26350.43700159  26586.49580334\n",
      "    -427.92651974  26606.36039838  27077.8718659   18849.53140124\n",
      "   14740.43856136  19643.13780883  45253.38330087   -579.16623097\n",
      "   48060.52275386  73205.92602179  75592.43201277 153937.1281469 ]\n",
      " [156039.30731806  42383.72721352  37634.69195385  37966.7414181\n",
      "    -615.42414275  37996.9500556   38666.79377666  26915.38320733\n",
      "   21049.4437441   28052.18660791  64626.405494     -823.13869411\n",
      "   68635.94268408 104548.37730639 107949.53796528 219837.14676063]\n",
      " [113659.04451606  30872.97440486  27410.68889977  27655.49941305\n",
      "    -445.76598131  27676.38957922  28166.31677833  19606.91716554\n",
      "   15333.05512645  20432.93690103  47073.2176931    -601.7415803\n",
      "   49993.47121924  76150.44006817  78631.66713148 160127.74812107]\n",
      " [135075.69145242  36689.85469893  32577.28424562  32866.51398757\n",
      "    -531.24700867  32891.71810931  33472.65862477  23300.29192119\n",
      "   18221.7914476   24283.12119443  55943.66473142   -713.57134674\n",
      "   59414.49856376  90501.11673954  93447.3770932  190301.58396082]\n",
      " [122572.57674703  33294.2123404   29560.2851069   29824.2777755\n",
      "    -480.73312928  29846.86430506  30375.2094227   21144.62490888\n",
      "   16535.46331113  22035.44129633  50764.85752884   -648.99647066\n",
      "   53914.00660609  82122.2576548   84798.27053719 172685.25603558]\n",
      " [170996.88111021  46446.49771114  41242.50514973  41605.99518626\n",
      "    -674.81439826  41639.33861233  42373.13600079  29495.31646391\n",
      "   23067.05428195  30741.30640434  70821.40919592   -901.86838916\n",
      "   75215.21400964 114570.38488412 118297.18861966 240910.21010593]\n",
      " [120534.02054415  32741.01048674  29067.62928566  29328.28755473\n",
      "    -471.66606226  29350.17962118  29870.58367194  20793.82726885\n",
      "   16260.57421346  21669.22919202  49920.35009599   -639.3837013\n",
      "   53016.54335221  80754.825824    83388.59388606 169811.86865773]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "/home/shuai/miniconda3/envs/d2l/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 假设你的数据已经准备好了\n",
    "# data 是输入特征\n",
    "# labels 是对应的标签\n",
    "\n",
    "# 将数据分割为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 对数据进行标准化处理\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 初始化MLP模型\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(16,32,64,32,16), max_iter=500, alpha=0.0001,\n",
    "                   solver='lbfgs', verbose=10, random_state=42, tol=0.0001)\n",
    "\n",
    "# 训练模型\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 使用测试数据进行评估\n",
    "score = mlp.score(X_test_scaled, y_test)\n",
    "print(\"Score:\", score)\n",
    "\n",
    "# 使用训练好的模型进行预测\n",
    "predictions = mlp.predict(X_test_scaled)\n",
    "\n",
    "# 打印预测结果\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
